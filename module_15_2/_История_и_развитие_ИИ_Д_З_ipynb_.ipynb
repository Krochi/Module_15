{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Домашнее задание"
      ],
      "metadata": {
        "id": "RKVH7ZaAezCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "\n",
        "Многослойный перцептрон (MLP) может решать задачи, которые однослойный перцептрон не способен решить, из-за своей способности моделировать нелинейные зависимости. Одним из классических примеров такой задачи является проблема \"исключающее ИЛИ\" (XOR).\n",
        "\n",
        "### Проблема XOR\n",
        "\n",
        "Логическая операция XOR возвращает истину только в том случае, если один из входов истинный, а другой ложный. Ниже приведена таблица истинности для XOR:\n",
        "\n",
        "| Вход 1 | Вход 2 | XOR |\n",
        "|--------|--------|-----|\n",
        "|   0    |   0    |  0  |\n",
        "|   0    |   1    |  1  |\n",
        "|   1    |   0    |  1  |\n",
        "|   1    |   1    |  0  |\n",
        "\n",
        "Эту задачу нельзя решить с помощью однослойного перцептрона, так как она не является линейно разделимой. Однако многослойный перцептрон, содержащий хотя бы один скрытый слой, способен решить эту задачу.\n",
        "\n",
        "\n",
        "Ниже приведен код решения задачи XOR **многослойным** персептроном.\n",
        "\n",
        "Разберите ее самостоятельно.\n",
        "\n",
        "После чего создайте новую кодовую ячейку. Скопируйте в нее код **однослойного** персептрона и попытайтесь решить задачу на 10 000, 20 000, 50 000 эпохах.\n",
        "\n",
        "Создайте текстовую ячейку и напишите в ней свои выводы об однослойных и многослойных персептронах.\n",
        "\n",
        "Сохраните колаб и пришлите на него ссылку преподавателю.\n"
      ],
      "metadata": {
        "id": "w6HGKktpbujp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DahpZ9PqbFEF"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения (XOR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция XOR\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=5000, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Скопируйте в код однослойного персептрона и попытайтесь решить задачу XOR на 10 000, 20 000, 50 000 эпохах."
      ],
      "metadata": {
        "id": "Du6zENjXkRvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Многослойный перцептрон с одним или более скрытыми слоями успешно справляется с задачей XOR, так как наличие скрытого слоя позволяет ему создавать более сложные нелинейные разделяющие поверхности, что и требуется для корректного решения задачи. Многослойный перцептрон (MLP) в приведённом выше примере имеет скрытый слой с 5 нейронами и активационную функцию ReLU, что позволяет ему моделировать нелинейные зависимости и успешно решать задачу XOR.\n",
        "\n",
        "2. Однослойный перцептрон (без скрытого слоя) не способен решить задачу XOR, поскольку она нелинейно разделима. Увеличение количества эпох в обучении однослойного перцептрона не позволяет ему правильно обучиться этой задаче, так как однослойный перцептрон не может моделировать нелинейные зависимости."
      ],
      "metadata": {
        "id": "gZ8HvQt6_Nh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "for epochs in [10000, 20000, 50000]:\n",
        "    print(f\"Перцептрон с {epochs} эпох:\")\n",
        "    slp = MLPClassifier(hidden_layer_sizes=(), activation='relu', max_iter=epochs, solver='adam')\n",
        "    slp.fit(X, y)\n",
        "\n",
        "    for xi in X:\n",
        "        print(f\"{xi} -> {slp.predict([xi])[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Py-D0N99Qe",
        "outputId": "cdeb94cb-9db6-4cf8-ff7e-ffd2006db36b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перцептрон с 10000 эпох:\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n",
            "Перцептрон с 20000 эпох:\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n",
            "Перцептрон с 50000 эпох:\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n"
          ]
        }
      ]
    }
  ]
}