# -*- coding: utf-8 -*-
""""История и развитие ИИ. Д.З.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10pC0Ndr1Ddzeu_jW_Jt_xWpN0tQd-bae

#Домашнее задание

### Задание

Многослойный перцептрон (MLP) может решать задачи, которые однослойный перцептрон не способен решить, из-за своей способности моделировать нелинейные зависимости. Одним из классических примеров такой задачи является проблема "исключающее ИЛИ" (XOR).

### Проблема XOR

Логическая операция XOR возвращает истину только в том случае, если один из входов истинный, а другой ложный. Ниже приведена таблица истинности для XOR:

| Вход 1 | Вход 2 | XOR |
|--------|--------|-----|
|   0    |   0    |  0  |
|   0    |   1    |  1  |
|   1    |   0    |  1  |
|   1    |   1    |  0  |

Эту задачу нельзя решить с помощью однослойного перцептрона, так как она не является линейно разделимой. Однако многослойный перцептрон, содержащий хотя бы один скрытый слой, способен решить эту задачу.


Ниже приведен код решения задачи XOR **многослойным** персептроном.

Разберите ее самостоятельно.

После чего создайте новую кодовую ячейку. Скопируйте в нее код **однослойного** персептрона и попытайтесь решить задачу на 10 000, 20 000, 50 000 эпохах.

Создайте текстовую ячейку и напишите в ней свои выводы об однослойных и многослойных персептронах.

Сохраните колаб и пришлите на него ссылку преподавателю.
"""

from sklearn.neural_network import MLPClassifier
import numpy as np

# Данные для обучения (XOR)
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 0])  # Операция XOR

# Создание и обучение MLP-классификатора
mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=5000, solver='adam')
mlp.fit(X, y)

# Тестирование
for xi in X:
    print(f"{xi} -> {mlp.predict([xi])[0]}")

#Скопируйте в код однослойного персептрона и попытайтесь решить задачу XOR на 10 000, 20 000, 50 000 эпохах.

"""1. Многослойный перцептрон с одним или более скрытыми слоями успешно справляется с задачей XOR, так как наличие скрытого слоя позволяет ему создавать более сложные нелинейные разделяющие поверхности, что и требуется для корректного решения задачи. Многослойный перцептрон (MLP) в приведённом выше примере имеет скрытый слой с 5 нейронами и активационную функцию ReLU, что позволяет ему моделировать нелинейные зависимости и успешно решать задачу XOR.

2. Однослойный перцептрон (без скрытого слоя) не способен решить задачу XOR, поскольку она нелинейно разделима. Увеличение количества эпох в обучении однослойного перцептрона не позволяет ему правильно обучиться этой задаче, так как однослойный перцептрон не может моделировать нелинейные зависимости.
"""

from sklearn.neural_network import MLPClassifier
import numpy as np

X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 0])

for epochs in [10000, 20000, 50000]:
    print(f"Перцептрон с {epochs} эпох:")
    slp = MLPClassifier(hidden_layer_sizes=(), activation='relu', max_iter=epochs, solver='adam')
    slp.fit(X, y)

    for xi in X:
        print(f"{xi} -> {slp.predict([xi])[0]}")