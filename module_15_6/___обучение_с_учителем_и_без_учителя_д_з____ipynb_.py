# -*- coding: utf-8 -*-
""""__Обучение с учителем и без учителя. Д.З___.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fOfCTQv0rs37XbX1811aQjWUU-WtDcYz

#Домашнее задание: Обучение с учителем и без учителя. Д.З

Обучение с учителем (supervised learning) и без учителя (unsupervised learning) — две основные парадигмы машинного обучения, которые используются для решения различных задач.

### Обучение с учителем (Supervised Learning)
Обучение с учителем включает в себя обучение модели на размеченных данных. Размеченные данные означают, что для каждого примера в наборе данных известен правильный ответ или метка.

#### Примеры задач обучения с учителем:
1. **Классификация**: Предсказание категории или класса, к которому принадлежит объект.
   - Пример: Распознавание изображений (определить, что изображено на картинке: кошка или собака).
2. **Регрессия**: Предсказание непрерывного значения.
   - Пример: Прогнозирование цен на недвижимость.

#### Основные этапы обучения с учителем:
1. **Сбор и разметка данных**: Подготовка набора данных, где каждый пример имеет метку.
2. **Разделение данных**: Деление набора данных на обучающую и тестовую части.
3. **Выбор модели**: Определение алгоритма, который будет использоваться для обучения (например, линейная регрессия, дерево решений).
4. **Обучение модели**: Использование обучающего набора данных для настройки параметров модели.
5. **Оценка модели**: Проверка качества модели на тестовом наборе данных.

### Обучение без учителя (Unsupervised Learning)
Обучение без учителя включает в себя обучение модели на неразмеченных данных. Модель должна самостоятельно выявить структуру или паттерны в данных.

#### Примеры задач обучения без учителя:
1. **Кластеризация**: Группировка объектов в кластеры на основе их сходства.
   - Пример: Сегментация клиентов по схожести их покупательских привычек.
2. **Поиск ассоциаций**: Выявление правил ассоциаций между объектами в данных.
   - Пример: Анализ рыночной корзины (какие продукты часто покупаются вместе).

#### Основные этапы обучения без учителя:
1. **Сбор данных**: Подготовка набора данных без меток.
2. **Выбор алгоритма**: Определение алгоритма, который будет использоваться для обучения (например, k-means, алгоритм ассоциации).
3. **Обучение модели**: Применение алгоритма к данным для выявления структур или паттернов.
4. **Интерпретация результатов**: Анализ полученных результатов и их интерпретация.

### Домашнее задание
Создайте копию блокнота. Далее выполнйте задания в ней.

1. **Теоретическая часть**:
   - Опишите различия между обучением с учителем и без учителя.
   - Приведите примеры задач, которые решаются с помощью обучения с учителем, и задачи, которые решаются с помощью обучения без учителя.

2. **Практическая часть**:
   - Найдите датасет, который можно использовать для обучения с учителем и без учителя. (Например, датасет "Wine" из библиотеки Scikit-Learn. Этот датасет содержит информацию о химическом составе различных вин и их классах (три разных сорта вина)).
   - Реализуйте  алгоритм обучения с учителем и без учителя. Интерпретируйте результаты.

```python
# Импортируем необходимые библиотеки
import numpy as np
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
```
Ссылку на ваш блокнот разместите в домашнем задании.

Удачи в выполнении задания! Если возникнут вопросы, не стесняйтесь обращаться за помощью.

### Обучение с учителем: Классификация с использованием логистической регрессии
Используем датасет "Iris" для классификации видов ирисов.
"""

# Импортируем необходимые библиотеки
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Загружаем датасет Iris
iris = load_iris()
X = iris.data
y = iris.target

# Разделяем данные на обучающую и тестовую части
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Обучаем модель логистической регрессии
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# Предсказываем результаты на тестовых данных
y_pred = model.predict(X_test)

# Оцениваем качество модели
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""##Пояснение к метрикам
###Accuracy:

**accuracy**: Доля правильно предсказанных классов среди всех предсказаний. В данном случае, accuracy равна 1.00 (или 100%), что означает, что модель правильно предсказала все 45 примеров.

###Macro Avg:

**macro** avg: Среднее арифметическое значения precision, recall и F1-score по всем классам. В данном случае все значения равны 1.00, что указывает на идеальную модель для всех классов.
precision: Доля правильно предсказанных положительных результатов среди всех предсказанных положительных результатов.
recall: Доля правильно предсказанных положительных результатов среди всех фактических положительных результатов.
f1-score: Среднее гармоническое значение precision и recall, что позволяет учесть оба этих параметра.


###Weighted Avg:

**weighted avg**: Взвешенное среднее значение precision, recall и F1-score по всем классам, где вес каждого класса пропорционален количеству истинных примеров этого класса. В данном случае все значения равны 1.00, что также указывает на идеальную модель.
Взвешенное среднее полезно, когда классы неравномерно распределены, так как оно учитывает количество примеров каждого класса.

### Обучение без учителя: Кластеризация с использованием алгоритма K-means
Используем тот же датасет "Iris" для кластеризации.
"""

# Импортируем необходимые библиотеки
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Обучаем модель K-means
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X)

# Предсказываем кластеры
clusters = kmeans.predict(X)

# Визуализируем результаты кластеризации
plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', marker='o')
plt.title('K-means Clustering of Iris Dataset')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.show()

"""
### Пояснение коду
1. **Обучение с учителем (Supervised Learning)**:
   - Загружаем датасет Iris.
   - Разделяем данные на обучающую и тестовую выборки.
   - Обучаем модель логистической регрессии на обучающей выборке.
   - Оцениваем модель на тестовой выборке, выводим точность и отчёт классификации.

2. **Обучение без учителя (Unsupervised Learning)**:
   - Загружаем датасет Iris.
   - Обучаем модель K-means для кластеризации данных.
   - Визуализируем результаты кластеризации, отображая кластеры на графике.
"""



"""#Решение ДЗ:
#Теоретическая часть:

#1. Обучение с учителем (Supervised Learning)
В обучении с учителем модель обучается на размеченных данных, то есть на примерах, которые содержат как входные данные, так и соответствующие им правильные ответы (метки). Цель модели — научиться предсказывать метки на основе входных данных, чтобы, получив новые, не размеченные данные, она могла правильно их классифицировать или регрессировать.

#2. Обучение без учителя (Unsupervised Learning)
В обучении без учителя модель обучается на неразмеченных данных, то есть без меток, и её задача — выявить скрытые структуры или закономерности в данных. Модель должна самостоятельно найти группы или паттерны, которые существуют в наборе данных.

#Практическая часть:

Найдите датасет, который можно использовать для обучения с учителем и без учителя. (Например, датасет "Wine" из библиотеки Scikit-Learn. Этот датасет содержит информацию о химическом составе различных вин и их классах (три разных сорта вина)).
Реализуйте алгоритм обучения с учителем и без учителя. Интерпретируйте результаты.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.decomposition import PCA

wine = load_wine()
X = wine.data
y = wine.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Обучение с учителем
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'solver': ['newton-cg']}

grid_search = GridSearchCV(LogisticRegression(max_iter=2000), param_grid, cv=5)
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy with optimized model:", accuracy)
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Обучение без учителя
pca = PCA(n_components=2)
X_train_2d = pca.fit_transform(X_train)
X_test_2d = pca.transform(X_test)

plt.figure(figsize=(8, 6))

plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap='viridis', marker='o', edgecolor='k', alpha=0.7)
plt.title('Training Data with Logistic Regression Classes')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.colorbar(label='Class')

xx, yy = np.meshgrid(np.linspace(X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1, 100),
                     np.linspace(X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1, 100))
Z = best_model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')
plt.show()