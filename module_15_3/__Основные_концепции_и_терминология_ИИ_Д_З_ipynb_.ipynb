{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "Ознакомьтесь с приведёнными ниже примерами использования алгоритмов МО и НС для решения задачи распознавания рукописных цифр.\n",
        "\n",
        "## Порядок выполнения ДЗ\n",
        "\n",
        "1. Сделайте копию данного блокнота себе на диск. Далее работайте со своей копией блокнота. Сохраняйте вносимые в неё изменения.\n",
        "2. Ознакомьтесь с теоретическим текстом и кодом из настоящего блокнота.\n",
        "3. Перенесите примеры кода в отдельные кодовые ячейки и выполните их.\n",
        "4. Создайте тестовую ячейку, куда запишите ответы на теоретические вопросы.\n",
        "5. Расшарьте блокнот и используйте ссылку как ответ на ДЗ."
      ],
      "metadata": {
        "id": "SeivPBkJjNUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Учебный пример: Рещение задачи классификация рукописных цифр с использованием машинного обучения, глубокого обучения и нейронных сетей\n",
        "\n",
        "В этом задании мы будем использовать набор данных MNIST, который содержит изображения рукописных цифр (от 0 до 9). Мы реализуем три различных подхода к классификации этих изображений:\n",
        "\n",
        "1. **Машинное обучение**: Используем метод k-ближайших соседей (k-NN).\n",
        "2. **Глубокое обучение**: Используем многослойный перцептрон (MLP).\n",
        "3. **Нейронные сети**: Используем сверточную нейронную сеть (CNN).\n",
        "\n",
        "### Шаг 1: Установка библиотек\n",
        "\n",
        "Установите необходимые библиотеки:\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn tensorflow keras\n",
        "```\n",
        "\n",
        "### Шаг 2: Загрузка и предобработка данных\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### Шаг 3: Алгоритм машинного обучения (k-NN)\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 4: Глубокое обучение (MLP)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 5: Нейронные сети (CNN)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')\n",
        "```\n",
        "\n",
        "### Заключение\n",
        "\n",
        "В этом задании мы реализовали три различных подхода к классификации изображений рукописных цифр с использованием средств машинного обучения (k-NN), глубокого обучения (MLP) и нейронных сетей (CNN). Мы увидели, что каждый из этих подходов имеет свои преимущества и недостатки, и что сложные модели глубокого обучения могут значительно улучшить точность классификации по сравнению с простыми моделями машинного обучения.\n",
        "\n",
        "### Теоритические вопросы\n",
        "\n",
        "1. Какие преимущества и недостатки использованных методов вы увидели?\n",
        "2. В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n",
        "3. Какие методы предобработки данных были использованы в этом задании?\n"
      ],
      "metadata": {
        "id": "vGMR-kTge1Wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDsO7Qm5e0px"
      },
      "outputs": [],
      "source": [
        "#Создайте необходимое количество кодовых ячеек и исполните в них приведенный выше код"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 1: Установка библиотек\n",
        "\n",
        "Установите необходимые библиотеки:\n",
        "\n"
      ],
      "metadata": {
        "id": "70dTMSyTNTI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn tensorflow keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YLf6QFpNa3O",
        "outputId": "6fccc39d-ed54-4708-c9ac-958cd5567b50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 2: Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "BK3mBKXbNmhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6doxyrSNuNQ",
        "outputId": "e483bde2-7008-4925-c7e8-1932c149b2bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 3: Алгоритм машинного обучения (k-NN)"
      ],
      "metadata": {
        "id": "XMm3UD2iPG6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjP_BNG-PLrw",
        "outputId": "b7b1f81d-1608-4872-bd5d-6e196702f801"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy of k-NN: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 4: Глубокое обучение (MLP)"
      ],
      "metadata": {
        "id": "Z08gBCrkPjz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vVNjfPxPlVi",
        "outputId": "5ed9e6e6-047d-4867-d458-129d7dd9f8bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.4643 - val_accuracy: 0.9509 - val_loss: 0.1662\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1218 - val_accuracy: 0.9614 - val_loss: 0.1267\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0788 - val_accuracy: 0.9712 - val_loss: 0.0952\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0564 - val_accuracy: 0.9727 - val_loss: 0.0913\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0403 - val_accuracy: 0.9690 - val_loss: 0.1101\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9890 - loss: 0.0338 - val_accuracy: 0.9749 - val_loss: 0.0914\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0286 - val_accuracy: 0.9724 - val_loss: 0.1021\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0237 - val_accuracy: 0.9705 - val_loss: 0.1218\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9925 - loss: 0.0213 - val_accuracy: 0.9744 - val_loss: 0.1037\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0164 - val_accuracy: 0.9754 - val_loss: 0.1089\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.1155\n",
            "Accuracy of MLP: 0.9757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 5: Нейронные сети (CNN)"
      ],
      "metadata": {
        "id": "eryjhdpAQLTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV1FVEmHQO5A",
        "outputId": "dcaf23a1-4a60-4a3b-85ac-7ef384823cb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 37ms/step - accuracy: 0.8092 - loss: 0.5800 - val_accuracy: 0.9795 - val_loss: 0.0620\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 39ms/step - accuracy: 0.9624 - loss: 0.1173 - val_accuracy: 0.9848 - val_loss: 0.0471\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 37ms/step - accuracy: 0.9758 - loss: 0.0819 - val_accuracy: 0.9878 - val_loss: 0.0413\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 37ms/step - accuracy: 0.9794 - loss: 0.0682 - val_accuracy: 0.9879 - val_loss: 0.0406\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.9818 - loss: 0.0580 - val_accuracy: 0.9899 - val_loss: 0.0335\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - accuracy: 0.9845 - loss: 0.0501 - val_accuracy: 0.9906 - val_loss: 0.0319\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 37ms/step - accuracy: 0.9851 - loss: 0.0478 - val_accuracy: 0.9904 - val_loss: 0.0312\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.9867 - loss: 0.0459 - val_accuracy: 0.9909 - val_loss: 0.0337\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37ms/step - accuracy: 0.9852 - loss: 0.0455 - val_accuracy: 0.9921 - val_loss: 0.0332\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37ms/step - accuracy: 0.9870 - loss: 0.0441 - val_accuracy: 0.9916 - val_loss: 0.0318\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0301\n",
            "Accuracy of CNN: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Заключение\n",
        "\n",
        "В этом задании мы реализовали три различных подхода к классификации изображений рукописных цифр с использованием средств машинного обучения (k-NN), глубокого обучения (MLP) и нейронных сетей (CNN). Мы увидели, что каждый из этих подходов имеет свои преимущества и недостатки, и что сложные модели глубокого обучения могут значительно улучшить точность классификации по сравнению с простыми моделями машинного обучения.\n",
        "\n",
        "#Теоритические вопросы\n",
        "Какие преимущества и недостатки использованных методов вы увидели?\n",
        "\n",
        "В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n",
        "\n",
        "Какие методы предобработки данных были использованы в этом задании?"
      ],
      "metadata": {
        "id": "VQcGe32ZUx0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преимущества и недостатки методов:\n",
        "\n",
        "#k-NN (K-ближайших соседей):\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "Простота: алгоритм не требует долгой настройки, работает как \"ленивый\" метод, то есть, запоминает данные и начинает работать только при необходимости классификации.\n",
        "Эффективен для небольших и средних наборов данных, особенно если есть достаточное количество памяти.\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "Требует много памяти, так как сохраняет все данные для классификации.\n",
        "Медленный на больших выборках, поскольку вычисление расстояний до всех соседей для каждого нового примера занимает много времени.\n",
        "Чувствителен к масштабированию данных и высокоразмерным данным.\n",
        "\n",
        "#MLP (Многослойный перцептрон):\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "Мощность в решении задач классификации и регрессии за счет нелинейных слоев, которые позволяют MLP решать более сложные задачи по сравнению с k-NN.\n",
        "Подходит для табличных данных и изображений в плоском формате (например, выровненные вектора пикселей).\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "Плохо работает с данными, которые имеют пространственную структуру (например, изображения). Структура MLP не использует пространственную информацию.\n",
        "Меньшая точность на задачах классификации изображений, чем у специализированных архитектур (например, CNN).\n",
        "\n",
        "#CNN (Сверточная нейронная сеть):\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "Способность выделять пространственные особенности (грани, узоры, объекты) благодаря сверточным слоям, что делает CNN особенно эффективной для задач компьютерного зрения.\n",
        "Выше точность на задачах классификации изображений, так как CNN автоматически выделяет важные признаки из изображений.\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "Более сложная архитектура, требующая настройки и значительных вычислительных ресурсов.\n",
        "Долгое обучение на больших выборках, требующее мощного оборудования.\n",
        "\n",
        "#Принципиальная разница между многослойным перцептроном (MLP) и сверточной нейронной сетью (CNN):\n",
        "\n",
        "1. Многослойный перцептрон (MLP) — это тип нейронной сети с несколькими полносвязными слоями, где каждый нейрон соединен с каждым нейроном следующего слоя. MLP подходит для обработки данных, представленных в плоской (векторной) форме. Он не учитывает пространственные взаимосвязи между признаками, что ограничивает его применение на задачах, где такие взаимосвязи важны, например, в обработке изображений.\n",
        "\n",
        "2. Сверточная нейронная сеть (CNN), напротив, содержит сверточные слои, которые способны захватывать пространственные структуры данных, такие как пиксели изображения, близкие по положению. CNN выделяет ключевые признаки изображения с помощью сверточных фильтров и пулинговых слоев, позволяя модели быть инвариантной к смещениям и искажениям, что делает CNN идеальной для обработки изображений.\n",
        "\n",
        "#Методы предобработки данных, использованные в этом задании:\n",
        "\n",
        "Нормализация данных: данные изображений были нормализованы, делением на 255, чтобы привести их значения к диапазону от 0 до 1. Это позволяет улучшить сходимость модели и стабилизировать обучение.\n",
        "\n",
        "1. One-Hot Encoding для меток: метки классов были преобразованы с помощью функции to_categorical, чтобы представить их как вектора one-hot для обучения MLP и CNN. Это формат, требуемый для использования с функцией потерь categorical_crossentropy.\n",
        "\n",
        "2. Реформатирование данных для CNN: изображения были преобразованы в четырехмерные тензоры формы (количество образцов, высота, ширина, каналы), чтобы позволить CNN работать с пространственными свойствами изображения."
      ],
      "metadata": {
        "id": "d2QsCwcVVoEv"
      }
    }
  ]
}