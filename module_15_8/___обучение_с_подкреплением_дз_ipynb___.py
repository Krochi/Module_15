# -*- coding: utf-8 -*-
""""__–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –î–ó.ipynb__"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CUruUF9jYz5d8PdsiY-J_GsT67Q47pif

#### –¶–µ–ª—å –∑–∞–¥–∞–Ω–∏—è:
–ü–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –æ—Å–Ω–æ–≤–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (Reinforcement Learning, RL), –ø–æ–Ω—è—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∏—Ö –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º Q-Learning –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.

#### –ó–∞–¥–∞–Ω–∏–µ:

1. **–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å:**
    - –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –æ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º: –∞–≥–µ–Ω—Ç, —Å—Ä–µ–¥–∞, –¥–µ–π—Å—Ç–≤–∏—è, –Ω–∞–≥—Ä–∞–¥—ã, —Å–æ—Å—Ç–æ—è–Ω–∏—è, –ø–æ–ª–∏—Ç–∏–∫–∞, —Ñ—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã.
    - –ù–∞–ø–∏—à–∏—Ç–µ –∫—Ä–∞—Ç–∫–æ–µ —ç—Å—Å–µ (1-2 —Å—Ç—Ä–∞–Ω–∏—Ü—ã) –æ —Ç–æ–º, –∫–∞–∫ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –¥—Ä—É–≥–∏—Ö –≤–∏–¥–æ–≤ –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º –∏ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è).

2. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å:**
    - –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º Q-Learning –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ "–ó–∞–º–∫–Ω—É—Ç—ã–π –ª–∞–±–∏—Ä–∏–Ω—Ç" (Gridworld).
    - –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø–æ–ª–∏—Ç–∏–∫—É –∏ —Ñ—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∞—à–∏–º –∞–≥–µ–Ω—Ç–æ–º.

3. **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è (–¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤):**
    - –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º SARSA –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å Q-Learning –Ω–∞ —Ç–æ–π –∂–µ –∑–∞–¥–∞—á–µ.
    - –ò–∑—É—á–∏—Ç–µ –∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π.

**–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ–º–µ—Å—Ç–∏—Ç–µ –≤ –æ–¥–∏–Ω –±–ª–æ–∫–Ω–æ—Ç Colab, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ, —Ä–∞—Å—à–∞—Ä—å—Ç–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ –Ω–∞–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É.**


#### –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–π 2 –∏ 3:

2. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å:**

    **–ß–∞—Å—Ç—å 1: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Q-Learning**
    - –°–æ–∑–¥–∞–π—Ç–µ —Å—Ä–µ–¥—É "Gridworld" —Ä–∞–∑–º–µ—Ä–æ–º 5x5. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–π—Ç–∏ –ø—É—Ç—å –æ—Ç —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –∫–ª–µ—Ç–∫–∏ (–≤ –ª–µ–≤–æ–º –≤–µ—Ä—Ö–Ω–µ–º —É–≥–ª—É) –¥–æ —Ü–µ–ª–µ–≤–æ–π –∫–ª–µ—Ç–∫–∏ (–≤ –ø—Ä–∞–≤–æ–º –Ω–∏–∂–Ω–µ–º —É–≥–ª—É), –∏–∑–±–µ–≥–∞—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π.
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Ñ–æ—Ä–º—É–ª—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-–∑–Ω–∞—á–µ–Ω–∏–π:

$
Q(s, a) \leftarrow Q(s, a) + \alpha [r + \gamma \max_{a'} Q(s', a') - Q(s, a)]
$

      –≥–¥–µ:
- $ s $ ‚Äî —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ,
- $ a $ ‚Äî —Ç–µ–∫—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ,
- $ r $ ‚Äî –Ω–∞–≥—Ä–∞–¥–∞,
- $ s' $ ‚Äî –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ,
- $ \alpha $ ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (learning rate),
- 4 \gamma $ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (discount factor).

    **–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞:**

    ```python
    import numpy as np

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    alpha = 0.1
    gamma = 0.9
    epsilon = 0.1
    episodes = 1000
    grid_size = 5

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
    Q = np.zeros((grid_size, grid_size, 4))

    # –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
    def choose_action(state):
        if np.random.rand() < epsilon:
            return np.random.randint(4)
        else:
            return np.argmax(Q[state])

    def update_q(state, action, reward, next_state):
        best_next_action = np.argmax(Q[next_state])
        td_target = reward + gamma * Q[next_state][best_next_action]
        td_error = td_target - Q[state][action]
        Q[state][action] += alpha * td_error

    # –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    for episode in range(episodes):
        state = (0, 0)
        done = False
        while not done:
            action = choose_action(state)
            next_state, reward, done = step(state, action)
            update_q(state, action, reward, next_state)
            state = next_state

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏
    policy = np.argmax(Q, axis=2)
    print("–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞:")
    print(policy)
    ```

    **–ß–∞—Å—Ç—å 2: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏**
    - –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É –∏ —Ñ—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.
    - –û–±—ä—è—Å–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ, –∫–∞–∫ –∞–≥–µ–Ω—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö.

3. **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è:**
    - –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º SARSA –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –µ–≥–æ —Å Q-Learning.
    - –í–Ω–µ–¥—Ä–∏—Ç–µ epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ.

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:

- –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ Q-Learning.
- –ö–∞—á–µ—Å—Ç–≤–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
- –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏–π (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ).

#–ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞

**–ü–æ–ª–∏—Ç–∏–∫–∞:** –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∞–≥–µ–Ω—Ç –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–≥—Ä–∞–¥—É.

------------
**–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏:** –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—É—é –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—É—é –Ω–∞–≥—Ä–∞–¥—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è Q-Learning
"""

import numpy as np

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
alpha = 0.1
gamma = 0.9
epsilon = 0.1
episodes = 1000
grid_size = 5

# –î–µ–π—Å—Ç–≤–∏—è: –≤–≤–µ—Ä—Ö, –≤–Ω–∏–∑, –≤–ª–µ–≤–æ, –≤–ø—Ä–∞–≤–æ
actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
Q = np.zeros((grid_size, grid_size, len(actions)))

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
def choose_action(state):
    if np.random.rand() < epsilon:
        return np.random.randint(len(actions))
    else:
        return np.argmax(Q[state])

def step(state, action):
    next_state = (state[0] + actions[action][0], state[1] + actions[action][1])
    if next_state[0] < 0 or next_state[0] >= grid_size or next_state[1] < 0 or next_state[1] >= grid_size:
        next_state = state  # –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –Ω–∞ –º–µ—Å—Ç–µ, –µ—Å–ª–∏ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã
    reward = 1 if next_state == (grid_size-1, grid_size-1) else -0.1
    done = next_state == (grid_size-1, grid_size-1)
    return next_state, reward, done

def update_q(state, action, reward, next_state):
    best_next_action = np.argmax(Q[next_state])
    td_target = reward + gamma * Q[next_state][best_next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
for episode in range(episodes):
    state = (0, 0)
    done = False
    while not done:
        action = choose_action(state)
        next_state, reward, done = step(state, action)
        update_q(state, action, reward, next_state)
        state = next_state

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏
policy = np.argmax(Q, axis=2)
print("–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞:")
print(policy)

"""–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏"""

import matplotlib.pyplot as plt

# –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏
value_function = np.max(Q, axis=2)

plt.figure(figsize=(10, 6))

# –ü–æ–ª–∏—Ç–∏–∫–∞
plt.subplot(1, 2, 1)
plt.title('–ü–æ–ª–∏—Ç–∏–∫–∞')
plt.imshow(policy, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, policy[i, j], ha='center', va='center', color='white')

# –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏
plt.subplot(1, 2, 2)
plt.title('–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏')
plt.imshow(value_function, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, round(value_function[i, j], 2), ha='center', va='center', color='white')

plt.show()

"""–†–µ–∞–ª–∏–∑–∞—Ü–∏—è SARSA"""

def update_sarsa_q(state, action, reward, next_state, next_action):
    td_target = reward + gamma * Q[next_state][next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SARSA
Q = np.zeros((grid_size, grid_size, len(actions)))
for episode in range(episodes):
    state = (0, 0)
    action = choose_action(state)
    done = False
    while not done:
        next_state, reward, done = step(state, action)
        next_action = choose_action(next_state)
        update_sarsa_q(state, action, reward, next_state, next_action)
        state, action = next_state, next_action

policy_sarsa = np.argmax(Q, axis=2)
print("–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ (SARSA):")
print(policy_sarsa)

"""–†–µ–∞–ª–∏–∑–∞—Ü–∏—è epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""

def update_sarsa_q(state, action, reward, next_state, next_action):
    td_target = reward + gamma * Q[next_state][next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SARSA
Q = np.zeros((grid_size, grid_size, len(actions)))
for episode in range(episodes):
    state = (0, 0)
    action = choose_action(state)
    done = False
    while not done:
        next_state, reward, done = step(state, action)
        next_action = choose_action(next_state)
        update_sarsa_q(state, action, reward, next_state, next_action)
        state, action = next_state, next_action

policy_sarsa = np.argmax(Q, axis=2)
print("–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ (SARSA):")
print(policy_sarsa)

"""#–†–ï–®–ï–ù–ò–ï:
#–û—Å–Ω–æ–≤—ã –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º

–í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ª–µ–∂–∞—Ç –≤ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL):

–ê–≥–µ–Ω—Ç ‚Äî —ç—Ç–æ –æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π —É—á–∏—Ç—Å—è. –û–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–æ–π –∏–ª–∏ —Ä–æ–±–æ—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥–æ–π.

–°—Ä–µ–¥–∞ (Environment) ‚Äî —ç—Ç–æ –≤—Å—ë, —Å —á–µ–º –∞–≥–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∏–≥—Ä–µ —Å—Ä–µ–¥–æ–π –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∞–º–∞ –∏–≥—Ä–∞, –∞ –≤ –∑–∞–¥–∞—á–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ–º ‚Äî –æ–∫—Ä—É–∂–∞—é—â–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ.

–°–æ—Å—Ç–æ—è–Ω–∏–µ (State) ‚Äî —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –≤ —Å—Ä–µ–¥–µ. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∏–≥—Ä–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏–≥—Ä–æ–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ, –µ–≥–æ –∑–¥–æ—Ä–æ–≤—å–µ –∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.

–î–µ–π—Å—Ç–≤–∏–µ (Action) ‚Äî —ç—Ç–æ –≤—ã–±–æ—Ä –∞–≥–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –æ–Ω –º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∏–≥—Ä–µ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–≤–∏–∂–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, —Å—Ç—Ä–µ–ª—å–±–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–æ–≤.

–í–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ (Reward) ‚Äî —ç—Ç–æ —á–∏—Å–ª–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–∞, –ø–æ–ª—É—á–∞–µ–º–∞—è –ø–æ—Å–ª–µ –µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º (–µ—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ –±—ã–ª–æ —Ö–æ—Ä–æ—à–∏–º) –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º (–µ—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ –±—ã–ª–æ –ø–ª–æ—Ö–∏–º).

–ü–æ–ª–∏—Ç–∏–∫–∞ (Policy) ‚Äî —ç—Ç–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∞–≥–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –æ–Ω –¥–æ–ª–∂–µ–Ω –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –ü–æ–ª–∏—Ç–∏–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π (–≤—Å–µ–≥–¥–∞ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤ –æ–¥–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏) –∏–ª–∏ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π (–¥–µ–π—Å—Ç–≤–∏—è –≤—ã–±–∏—Ä–∞—é—Ç—Å—è —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é).

–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (Value Function) ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç "—Ü–µ–Ω–Ω–æ—Å—Ç—å" –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è-–¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–µ–π—Å—Ç–≤–∏–π, –ø–æ–º–æ–≥–∞—è –∞–≥–µ–Ω—Ç—É –≤—ã–±–∏—Ä–∞—Ç—å –Ω–∞–∏–ª—É—á—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è.

–ú–æ–¥–µ–ª—å —Å—Ä–µ–¥—ã ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ. –≠—Ç–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å —É–ª—É—á—à–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.

#–û—Ñ—Ñ–ª–∞–π–Ω –∏ –æ–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ
Off-policy (–Ω–∞–ø—Ä–∏–º–µ—Ä, Q-Learning) ‚Äî –∞–≥–µ–Ω—Ç –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ –¥—Ä—É–≥–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ, –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π. –í Q-Learning –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –æ—Ç–ª–∏—á–Ω–∞—è –æ—Ç —Ç–æ–π, –∫–æ—Ç–æ—Ä—É—é –∞–≥–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–≥–µ–Ω—Ç—ã –º–æ–≥—É—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –Ω–æ –∏—Ö –ø–æ–ª–∏—Ç–∏–∫–∞ –±—É–¥–µ—Ç –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Q-–∑–Ω–∞—á–µ–Ω–∏—è).

On-policy (–Ω–∞–ø—Ä–∏–º–µ—Ä, SARSA) ‚Äî –∞–≥–µ–Ω—Ç —É—á–∏—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ –¥–µ–π—Å—Ç–≤–∏—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ —Ç–µ–∫—É—â–µ–π –ø–æ–ª–∏—Ç–∏–∫–µ. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-–∑–Ω–∞—á–µ–Ω–∏–π –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞–µ—Ç.

#–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
1. Q-—Ü–µ–Ω–Ω–æ—Å—Ç—å
Q-—Ü–µ–Ω–Ω–æ—Å—Ç—å (
ùëÑ
(
ùë†
,
ùëé
)
Q(s,a)) ‚Äî —ç—Ç–æ –º–µ—Ä–∞ —Ç–æ–≥–æ, –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤—ã–≥–æ–¥–Ω–æ –∞–≥–µ–Ω—Ç—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ
ùëé
a –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
ùë†
s. –û–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—É—é —Å—É–º–º—É –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π –æ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ –≤ –±—É–¥—É—â–µ–º.

Q-—Ü–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–º –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥–æ–π. –§–æ—Ä–º—É–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–¥–ª—è Q-Learning) –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –Ω–æ –∏ –æ–∂–∏–¥–∞–µ–º–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –≤ –±—É–¥—É—â–µ–º.

2. –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è
–°—É—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Q-Learning –∏ SARSA –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É–º–º—É –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π (–∏–ª–∏ "–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ"). –ß—Ç–æ–±—ã —ç—Ç–æ –¥–æ—Å—Ç–∏—á—å, –∞–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ Q-—Ñ—É–Ω–∫—Ü–∏—è. –ü–∞—Ä–∞–º–µ—Ç—Ä
ùõæ
Œ≥ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è) –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –±—É–¥—É—â–∏—Ö –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π. –ß–µ–º –±–ª–∏–∂–µ
ùõæ
Œ≥ –∫ 1, —Ç–µ–º –≤–∞–∂–Ω–µ–µ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è.

3. –ö–ª—é—á–µ–≤–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Q-Learning –∏ SARSA
Q-Learning –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π –¥–µ–π—Å—Ç–≤–∏–π, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –∞–≥–µ–Ω—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤—ã–±–µ—Ä–µ—Ç. –ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª—è–µ—Ç Q-—Ü–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –±–æ–ª–µ–µ "–∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º" –≤ –ø–æ–∏—Å–∫–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏.

SARSA, –Ω–∞–ø—Ä–æ—Ç–∏–≤, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-—Ü–µ–Ω–Ω–æ—Å—Ç–∏, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –±–æ–ª–µ–µ "–æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–º" –∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –Ω–∞ —Ç–µ–∫—É—â—É—é –ø–æ–ª–∏—Ç–∏–∫—É –∞–≥–µ–Ω—Ç–∞. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–µ–Ω, —Ç–∞–∫ –∫–∞–∫ –Ω–µ –¥–µ–ª–∞–µ—Ç —Å–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –æ —Ç–æ–º, –∫–∞–∫ –±—É–¥–µ—Ç –≤–µ—Å—Ç–∏ —Å–µ–±—è –∞–≥–µ–Ω—Ç –≤ –±—É–¥—É—â–µ–º.

#–ê–ª–≥–æ—Ä–∏—Ç–º epsilon-greedy
–ó–∞—á–µ–º –Ω—É–∂–Ω–∞ epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—è?
–ê–ª–≥–æ—Ä–∏—Ç–º epsilon-greedy –∏–≥—Ä–∞–µ—Ç –≤–∞–∂–Ω—É—é —Ä–æ–ª—å –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (exploration) –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (exploitation):

–≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è ‚Äî –∞–≥–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –¥–∞—ë—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –æ–∂–∏–¥–∞–µ–º–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç—É –±—ã—Å—Ç—Ä–æ –Ω–∞—É—á–∏—Ç—å—Å—è —Ö–æ—Ä–æ—à–æ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å—Ä–µ–¥–µ.
–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ ‚Äî –∞–≥–µ–Ω—Ç –∏–Ω–æ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è–º –≤ –±—É–¥—É—â–µ–º.
–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ epsilon-greedy:
–° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
1
‚àí
ùúñ
1‚àíœµ –∞–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º Q-–∑–Ω–∞—á–µ–Ω–∏–µ–º –≤ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ (—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è).
–° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
ùúñ
œµ –∞–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ).
–ö–æ–≥–¥–∞ –∞–≥–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ, –æ–Ω –±–æ–ª—å—à–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç (–±–æ–ª—å—à–æ–π
ùúñ
œµ) –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (–º–µ–Ω—å—à–∏–π
ùúñ
œµ). –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç—É —Å–Ω–∞—á–∞–ª–∞ –∏–∑—É—á–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –∞ –∑–∞—Ç–µ–º –Ω–∞—á–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.

–ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è —Å epsilon-greedy:
–ü—Ä–æ–±–ª–µ–º–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–≥–æ
ùúñ
œµ ‚Äî –µ—Å–ª–∏
ùúñ
œµ —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫–æ, –∞–≥–µ–Ω—Ç –±—É–¥–µ—Ç —á–∞—Å—Ç–æ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, —á—Ç–æ –∑–∞–º–µ–¥–ª–∏—Ç –æ–±—É—á–µ–Ω–∏–µ.
–ü—Ä–æ–±–ª–µ–º–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ–≥–æ
ùúñ
œµ ‚Äî –µ—Å–ª–∏
ùúñ
œµ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ, –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –∑–∞—Å—Ç—Ä—è—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –º–∞–∫—Å–∏–º—É–º–µ, –Ω–µ –∏—Å—Å–ª–µ–¥—É—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.
–ß—Ç–æ–±—ã —Ä–µ—à–∏—Ç—å —ç—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã,
ùúñ
œµ –æ–±—ã—á–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –ø–æ –º–µ—Ä–µ –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å 1.0 –¥–æ 0.1), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç—É –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –æ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∫ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏.

#–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã epsilon-greedy
–ò–Ω–æ–≥–¥–∞ epsilon-greedy –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π, –Ω–∞–ø—Ä–∏–º–µ—Ä:

Softmax —Å—Ç—Ä–∞—Ç–µ–≥–∏—è ‚Äî –≤–º–µ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é, –æ–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ Q-–∑–Ω–∞—á–µ–Ω–∏—è. –ß–µ–º –≤—ã—à–µ Q-—Ü–µ–Ω–Ω–æ—Å—Ç—å, —Ç–µ–º –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ —ç—Ç–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è.

Upper Confidence Bound (UCB) ‚Äî —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Ç–æ–ª—å–∫–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –Ω–æ –∏ —Å—Ç–µ–ø–µ–Ω—å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –¥–µ–π—Å—Ç–≤–∏—é, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è.

–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º ‚Äî —ç—Ç–æ –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á, –≥–¥–µ –∞–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –Ω–∞—É—á–∏—Ç—å—Å—è –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å–ª–æ–∂–Ω–æ–π —Å—Ä–µ–¥–µ. –ê–ª–≥–æ—Ä–∏—Ç–º—ã Q-Learning –∏ SARSA –ø–æ–∑–≤–æ–ª—è—é—Ç –∞–≥–µ–Ω—Ç–∞–º –Ω–∞—Ö–æ–¥–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–ª–∏—Ç–∏–∫–∏, –æ—Ü–µ–Ω–∏–≤–∞—è –¥–µ–π—Å—Ç–≤–∏—è —á–µ—Ä–µ–∑ Q-—Ñ—É–Ω–∫—Ü–∏—é. –û–±–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏.

–í–∞–∂–Ω–æ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–º —É—Ä–æ–≤–Ω–µ, –Ω–æ –∏ –Ω–∞—É—á–∏—Ç—å—Å—è –∏—Ö –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é. –í–∞–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≥–ª—É–±–ª—è—Ç—å—Å—è –≤ –¥–µ—Ç–∞–ª–∏, —É—á–∏—Ç—ã–≤–∞—è, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —á–∞—Å—Ç–æ —Ç—Ä–µ–±—É–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏.

–ò—Ç–∞–∫, —á—Ç–æ–±—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —ç—Ç–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö, –Ω–∞—á–∏–Ω–∞—é—â–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:

–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—ã Q-Learning –∏ SARSA –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ –ª–∞–±–∏—Ä–∏–Ω—Ç—ã –∏–ª–∏ –∏–≥—Ä—ã.
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
ùõæ
Œ≥,
ùõº
Œ±, –∏
ùúñ
œµ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∏—Ö –≤–ª–∏—è–Ω–∏—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞.
–ò–∑—É—á–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –º–µ—Ç–æ–¥—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ Deep Q-Networks (DQN), –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ Q-—Ñ—É–Ω–∫—Ü–∏–∏ –≤ —Å–ª–æ–∂–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö.

#–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏. —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Q-Learning

–≠—Ç–æ—Ç –∫–æ–¥ –æ–±—É—á–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –ª–∞–±–∏—Ä–∏–Ω—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Q-Learning, –∞ –∑–∞—Ç–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É, –≥–¥–µ –∫–∞–∂–¥–æ–µ —á–∏—Å–ª–æ –Ω–∞ –∫–ª–µ—Ç–∫–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –¥–µ–π—Å—Ç–≤–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0 ‚Äî –≤–≤–µ—Ä—Ö, 1 ‚Äî –≤–Ω–∏–∑, 2 ‚Äî –≤–ª–µ–≤–æ, 3 ‚Äî –≤–ø—Ä–∞–≤–æ).
"""

import numpy as np
import matplotlib.pyplot as plt

alpha = 0.1
gamma = 0.9
epsilon = 0.1
episodes = 1000
grid_size = 5

# –î–µ–π—Å—Ç–≤–∏—è: –≤–≤–µ—Ä—Ö, –≤–Ω–∏–∑, –≤–ª–µ–≤–æ, –≤–ø—Ä–∞–≤–æ
actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
Q = np.zeros((grid_size, grid_size, len(actions)))

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
def choose_action(state):
    if np.random.rand() < epsilon:
        return np.random.randint(len(actions))
    else:
        return np.argmax(Q[state])

def step(state, action):
    next_state = (state[0] + actions[action][0], state[1] + actions[action][1])
    if next_state[0] < 0 or next_state[0] >= grid_size or next_state[1] < 0 or next_state[1] >= grid_size:
        next_state = state
    reward = 1 if next_state == (grid_size-1, grid_size-1) else -0.1
    done = next_state == (grid_size-1, grid_size-1)
    return next_state, reward, done

def update_q(state, action, reward, next_state):
    best_next_action = np.argmax(Q[next_state])
    td_target = reward + gamma * Q[next_state][best_next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
for episode in range(episodes):
    state = (0, 0)
    done = False
    while not done:
        action = choose_action(state)
        next_state, reward, done = step(state, action)
        update_q(state, action, reward, next_state)
        state = next_state

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏
policy = np.argmax(Q, axis=2)
value_function = np.max(Q, axis=2)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.figure(figsize=(10, 6))

#–ü–æ–ª–∏—Ç–∏–∫–∞
plt.subplot(1, 2, 1)
plt.title('–ü–æ–ª–∏—Ç–∏–∫–∞')
plt.imshow(policy, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, policy[i, j], ha='center', va='center', color='white')

# –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏
plt.subplot(1, 2, 2)
plt.title('–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏')
plt.imshow(value_function, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, round(value_function[i, j], 2), ha='center', va='center', color='white')

plt.tight_layout()
plt.show()

"""#–†–µ–∞–ª–∏–∑–∞—Ü–∏—è SARSA"""

import numpy as np
import matplotlib.pyplot as plt

alpha = 0.1
gamma = 0.9
epsilon = 0.1
episodes = 1000
grid_size = 5

# –î–µ–π—Å—Ç–≤–∏—è: –≤–≤–µ—Ä—Ö, –≤–Ω–∏–∑, –≤–ª–µ–≤–æ, –≤–ø—Ä–∞–≤–æ
actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
Q = np.zeros((grid_size, grid_size, len(actions)))

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
def choose_action(state):
    if np.random.rand() < epsilon:
        return np.random.randint(len(actions))
    else:
        return np.argmax(Q[state])

def step(state, action):
    next_state = (state[0] + actions[action][0], state[1] + actions[action][1])
    if next_state[0] < 0 or next_state[0] >= grid_size or next_state[1] < 0 or next_state[1] >= grid_size:
        next_state = state
    reward = 1 if next_state == (grid_size-1, grid_size-1) else -0.1
    done = next_state == (grid_size-1, grid_size-1)
    return next_state, reward, done

def update_sarsa_q(state, action, reward, next_state, next_action):
    td_target = reward + gamma * Q[next_state][next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SARSA
for episode in range(episodes):
    state = (0, 0)
    action = choose_action(state)
    done = False
    while not done:
        next_state, reward, done = step(state, action)
        next_action = choose_action(next_state)
        update_sarsa_q(state, action, reward, next_state, next_action)
        state, action = next_state, next_action

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏
policy_sarsa = np.argmax(Q, axis=2)
value_function_sarsa = np.max(Q, axis=2)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.figure(figsize=(10, 6))

# –ü–æ–ª–∏—Ç–∏–∫–∞
plt.subplot(1, 2, 1)
plt.title('–ü–æ–ª–∏—Ç–∏–∫–∞ (SARSA)')
plt.imshow(policy_sarsa, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, policy_sarsa[i, j], ha='center', va='center', color='white')

# –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏
plt.subplot(1, 2, 2)
plt.title('–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (SARSA)')
plt.imshow(value_function_sarsa, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, round(value_function_sarsa[i, j], 2), ha='center', va='center', color='white')

plt.tight_layout()
plt.show()

"""#–†–µ–∞–ª–∏–∑–∞—Ü–∏—è epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""

import numpy as np
import matplotlib.pyplot as plt

alpha = 0.1
gamma = 0.9
epsilon = 0.1
episodes = 1000
grid_size = 5

# –î–µ–π—Å—Ç–≤–∏—è: –≤–≤–µ—Ä—Ö, –≤–Ω–∏–∑, –≤–ª–µ–≤–æ, –≤–ø—Ä–∞–≤–æ
actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-—Ç–∞–±–ª–∏—Ü—ã
Q = np.zeros((grid_size, grid_size, len(actions)))

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π —Å epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
def choose_action(state):
    if np.random.rand() < epsilon:
        return np.random.randint(len(actions))
    else:
        return np.argmax(Q[state])

def step(state, action):
    next_state = (state[0] + actions[action][0], state[1] + actions[action][1])
    if next_state[0] < 0 or next_state[0] >= grid_size or next_state[1] < 0 or next_state[1] >= grid_size:
        next_state = state
    reward = 1 if next_state == (grid_size-1, grid_size-1) else -0.1
    done = next_state == (grid_size-1, grid_size-1)
    return next_state, reward, done

def update_q(state, action, reward, next_state):
    best_next_action = np.argmax(Q[next_state])
    td_target = reward + gamma * Q[next_state][best_next_action]
    td_error = td_target - Q[state][action]
    Q[state][action] += alpha * td_error

# –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
for episode in range(episodes):
    state = (0, 0)
    done = False
    while not done:
        action = choose_action(state)
        next_state, reward, done = step(state, action)
        update_q(state, action, reward, next_state)
        state = next_state

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏
policy_epsilon_greedy = np.argmax(Q, axis=2)
value_function_epsilon_greedy = np.max(Q, axis=2)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.figure(figsize=(10, 6))

# –ü–æ–ª–∏—Ç–∏–∫–∞
plt.subplot(1, 2, 1)
plt.title('–ü–æ–ª–∏—Ç–∏–∫–∞ (epsilon-greedy)')
plt.imshow(policy_epsilon_greedy, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, policy_epsilon_greedy[i, j], ha='center', va='center', color='white')

# –§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏
plt.subplot(1, 2, 2)
plt.title('–§—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (epsilon-greedy)')
plt.imshow(value_function_epsilon_greedy, cmap='viridis', origin='upper')
for i in range(grid_size):
    for j in range(grid_size):
        plt.text(j, i, round(value_function_epsilon_greedy[i, j], 2), ha='center', va='center', color='white')

plt.tight_layout()
plt.show()

"""#–ó–∞–∫–ª—é—á–µ–Ω–∏–µ
–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥–æ–π. –ê–ª–≥–æ—Ä–∏—Ç–º—ã Q-Learning –∏ SARSA ‚Äî —ç—Ç–æ –¥–≤–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–µ—Ç–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç Q-—Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π. epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–º–æ–≥–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–µ–∂–¥—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–µ–π —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π.

–ö–∞–∂–¥—ã–π –∏–∑ —ç—Ç–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏–º–µ–µ—Ç —Å–≤–æ–∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –∏ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, Q-Learning –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø–æ–∏—Å–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–µ–∫—É—â–µ–π –ø–æ–ª–∏—Ç–∏–∫–∏, –∞ SARSA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –±–æ–ª–µ–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–º.

–° –ø–æ–º–æ—â—å—é —ç—Ç–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –º–æ–∂–Ω–æ —Ä–µ—à–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏, –≤–∫–ª—é—á–∞—è –∏–≥—Ä—ã, –∑–∞–¥–∞—á–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –¥–∞–∂–µ –∑–∞–¥–∞—á–∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∏, –≥–¥–µ –∞–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –æ–±—É—á–∞—Ç—å—Å—è –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–µ–π—Å—Ç–≤–∏—è –≤ —Å–ª–æ–∂–Ω–æ–π —Å—Ä–µ–¥–µ.
"""